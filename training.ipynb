{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whole training pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook outlines the entire training pipeline used to develop the seven models included in our ensemble for the submission. To enhance readability, we have imported custom functions from various Python files within this GitHub repository. Unlike [`inference.ipynb`](inference.ipynb), this notebook cannot function as a standalone file.\n",
    "\n",
    "We detail our complete training process in different steps: \n",
    "1. Converting the csv training data in a yolo format for training\n",
    "2. Training uncurated yolo models in cross validation 5 folds\n",
    "3. Use the 5 folds to curate their corresponding validation data in 2 different ways and save curated data in new csv files.\n",
    "4. Create the yolo datasets corresponding to the curated training csv\n",
    "5. Train the 7 models used for the ensembling \n",
    "\n",
    "This figure summarizes the training process:\n",
    "\n",
    "<img src=\"images/training.png\" alt=\"training process\" height=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first need to install some python packages: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed installations\n",
    "!pip3 install pandas\n",
    "!pip3 install tqdm\n",
    "!pip3 install pillow\n",
    "!pip3 install ultralytics # install automatically the last version of PyTorch and Torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And to import the necessary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "\n",
    "from detection import YoloConfig, YoloTrainer, YoloInference\n",
    "from notebooks.utils_notebook import split_dataset_from_csv,curate_image\n",
    "from utils import get_device\n",
    "\n",
    "\n",
    "# Please set the path to the data folder (where images and annotations are stored)\n",
    "data_folder='path/to/data/folder'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting the csv training data in a yolo format for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step was to convert the training data from the train.csv to a format compatible with YOLO. This is pretty straightforward, we copy the image in an images folder and we create the labels in a labels folder. Each `image.jpg` has a corresponding `image.txt` regrouping the different detections within the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=f\"{data_folder}/Cytologia/images/\"\n",
    "new_data_path=f\"{data_folder}/Cytologia_yolo/\"\n",
    "os.makedirs(new_data_path,exist_ok=True)\n",
    "csv_path=f\"{data_folder}/Cytologia/train.csv\"\n",
    "\n",
    "split_dataset_from_csv(new_data_path,data_path, csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training uncurated yolo models in cross validation 5 folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our `YoloConfig` and `YoloTrainer` efficiently manage cross-validation by simply setting the `fold` parameter to the desired number of folds. If `fold` is set to one (or left undefined), cross-validation is not applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=get_device()\n",
    "\n",
    "classes=['B', 'BA', 'EO', 'Er', 'LAM3', 'LF', 'LGL', 'LH_lyAct', 'LLC', 'LM', 'LY', 'LZMG', 'LyB', 'Lysee', 'M', 'MBL', 'MM', 'MO', 'MoB', 'PM', 'PNN', 'SS', 'Thromb']\n",
    "\n",
    "conf=YoloConfig(\n",
    "    dataset=f\"{data_folder}/Cytologia_yolo\", # WARNING : path must be an absolute path\n",
    "    backbone=\"yolo11n.pt\",\n",
    "    img_size=384, # Reduced image size to 384 for faster training and inference\n",
    "    identifier=\"no_curation\",\n",
    "    nc=23,\n",
    "    classes=classes,\n",
    "    device=device,\n",
    "    epochs=100, \n",
    "    batch_size=64,\n",
    "    folds=5, \n",
    ")\n",
    "trainer=YoloTrainer(conf)\n",
    "trainer.train()\n",
    "\n",
    "del trainer\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the 5 folds to curate their corresponding validation data in 2 different ways and save curated data in new csv files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training, we cleaned the dataset as follows:\n",
    "\n",
    "- For each YOLO model, we predicted bounding boxes and classes on the validation data.\n",
    "\n",
    "- We matched the ground truth boxes provided in the train.csv with the YOLO predictions, retaining the YOLO bounding boxes (which were empirically more accurate than the manual annotations) while preserving the ground truth class.\n",
    "\n",
    "- For YOLO detections with a sufficient score that did not match any ground truth boxes, we masked the corresponding part of the image with a black mask to ensure no unannotated cells remained in the training dataset (whether they were WBCs at the border or unannotated WBCs) (see left figure).\n",
    "\n",
    "- *Optionnal*: For ground truth boxes with no matching YOLO boxes (IoU < 0.4), we also masked these bounding boxes, assuming they could be incorrect annotations (see right figure).\n",
    "\n",
    "The figure below illustrates the cleaning procedure we described.\n",
    "\n",
    "<img src=\"images/curation1.png\" alt=\"Curation process 1\" height=\"400\"/>    <img src=\"images/curation2.png\" alt=\"Curation process 2\" height=\"400\"/>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentionned in the [`README.md`](README.md), the final curation step is *optional*. We created two versions of the dataset: one with this curation step and one without, to increase variability in the data used to train our models.    \n",
    "\n",
    "Here is the code used to create the 2 new csv train files corresponding to the 2 curated datasets: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For the first dataset**: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode=\"msk_iou\"\n",
    "\n",
    "origin_csv_path=f\"{data_folder}/Cytologia/train.csv\"\n",
    "\n",
    "csv_path=f\"{data_folder}/Cytologia/train_{mode}.csv\"\n",
    "if not os.path.exists(csv_path):\n",
    "    shutil.copy(origin_csv_path,csv_path)\n",
    "else:\n",
    "    raise ValueError(\"File already exists\")\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "images_list = df[\"NAME\"].unique()\n",
    "path=f\"{data_folder}/Cytologia/images/\"\n",
    "\n",
    "def get_jpg_files_from_directory(directory_path):\n",
    "    jpg_files = [f for f in os.listdir(directory_path) if f.endswith('.jpg')]\n",
    "    return jpg_files\n",
    "\n",
    "weights_path=\"models/detection/Cytologia_yolo/yolo11n/384/no_curation_cv/\"\n",
    "\n",
    "# count number of folders (one per fold) to find k\n",
    "k=len([name for name in os.listdir(weights_path) if os.path.isdir(os.path.join(weights_path, name))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(k):\n",
    "    print(f\"fold{i+1}/{k}\")\n",
    "    val_txt=weights_path+f\"val_fold{i}.txt\"\n",
    "    yolo_engine=YoloInference(f\"{weights_path}/fold_{i}/train/weights/best.pt\",device=\"cuda\")\n",
    "\n",
    "    with open(val_txt) as f:\n",
    "        list_image_paths = f.readlines()\n",
    "    list_image_paths = [x.strip() for x in list_image_paths]\n",
    "\n",
    "    new_data = []\n",
    "    tqdm_fold=tqdm(list_image_paths,desc=\"Processing images\",unit=\"image\")\n",
    "    \n",
    "    for img_path in tqdm_fold:\n",
    "        name=img_path.split(\"/\")[-1]\n",
    "        df_img=df[df['NAME']==name]\n",
    "        boxes = df_img[['x1', 'y1', 'x2', 'y2']].apply(tuple, axis=1).tolist()\n",
    "        classes = df_img['class'].tolist()\n",
    "        yolo_output=yolo_engine.predict(img_path)\n",
    "        curate_image(boxes,yolo_output,img_path,classes,df,new_data,mode=mode)\n",
    "\n",
    "    del yolo_engine\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    if new_data:\n",
    "        df = pd.concat([df, pd.DataFrame(new_data)], ignore_index=True)                          \n",
    "\n",
    "df.to_csv(csv_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For the second dataset**: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode=\"msk_blk\"\n",
    "\n",
    "origin_csv_path=f\"{data_folder}/Cytologia/train.csv\"\n",
    "\n",
    "csv_path=f\"{data_folder}/Cytologia/train_{mode}.csv\"\n",
    "if not os.path.exists(csv_path):\n",
    "    shutil.copy(origin_csv_path,csv_path)\n",
    "else:\n",
    "    raise ValueError(\"File already exists\")\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "images_list = df[\"NAME\"].unique()\n",
    "path=f\"{data_folder}/Cytologia/images/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(k):\n",
    "    print(f\"fold{i+1}/{k}\")\n",
    "    val_txt=weights_path+f\"val_fold{i}.txt\"\n",
    "    yolo_engine=YoloInference(f\"{weights_path}/fold_{i}/train/weights/best.pt\",device=\"cuda\")\n",
    "\n",
    "    with open(val_txt) as f:\n",
    "        list_image_paths = f.readlines()\n",
    "    list_image_paths = [x.strip() for x in list_image_paths]\n",
    "\n",
    "    new_data = []\n",
    "    tqdm_fold=tqdm(list_image_paths,desc=\"Processing images\",unit=\"image\")\n",
    "    \n",
    "    for img_path in tqdm_fold:\n",
    "        name=img_path.split(\"/\")[-1]\n",
    "        df_img=df[df['NAME']==name]\n",
    "        boxes = df_img[['x1', 'y1', 'x2', 'y2']].apply(tuple, axis=1).tolist()\n",
    "        classes = df_img['class'].tolist()\n",
    "        yolo_output=yolo_engine.predict(img_path)\n",
    "        curate_image(boxes,yolo_output,img_path,classes,df,new_data,mode=mode)\n",
    "\n",
    "    del yolo_engine\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    if new_data:\n",
    "        df = pd.concat([df, pd.DataFrame(new_data)], ignore_index=True)                          \n",
    "\n",
    "df.to_csv(csv_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the yolo datasets corresponding to the curated training csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will create the 2 datasets in the yolo format corresponding to the 2 newly created csv:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modes=[\"msk_iou\",\"msk_blk\"]\n",
    "data_path=f\"{data_folder}/Cytologia/images/\"\n",
    "\n",
    "for mode in modes: \n",
    "    new_data_path=f\"{data_folder}/Cytologia_{mode}/\"\n",
    "    os.makedirs(new_data_path,exist_ok=True)\n",
    "    csv_path=f\"{data_folder}/Cytologia/train_{mode}.csv\"\n",
    "    split_dataset_from_csv(new_data_path,data_path, csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the 7 models used for the ensembling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all the necessary datasets prepared, we will train the seven models for ensembling:\n",
    "\n",
    "- **3 models on the curated dataset 1**: Yolo11m, Yolo11x, and Yolov10m\n",
    "- **3 models on the curated dataset 2**: Yolo11n, Yolov10n, and Yolov10s\n",
    "- **1 model on the uncurated dataset**: Yolo11n  \n",
    "\n",
    "We prioritized using smaller YOLO models (except for Yolo11x) to maintain relatively low inference time, even with an ensemble of seven models.\n",
    "\n",
    "If you need a single model to meet inference speed constraints, I recommend using Yolo11m trained on dataset1 for the best standalone performance or Yolo11n trained on dataset1 for optimal inference speed with good performance. Details about inference speed are available in thee [`README.md`](README.md) and the [`inference.ipynb`](inference.ipynb) files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training yolo models on dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode=\"msk_iou\"\n",
    "\n",
    "device=get_device()\n",
    "\n",
    "classes=['B', 'BA', 'EO', 'Er', 'LAM3', 'LF', 'LGL', 'LH_lyAct', 'LLC', 'LM', 'LY', 'LZMG', 'LyB', 'Lysee', 'M', 'MBL', 'MM', 'MO', 'MoB', 'PM', 'PNN', 'SS', 'Thromb']\n",
    "\n",
    "backbones=[\"yolo11m.pt\",\"yolo11x.pt\",\"yolov10m.pt\"]\n",
    "\n",
    "for backbone in backbones:\n",
    "    conf=YoloConfig(\n",
    "        dataset=f\"{data_folder}/Cytologia_{mode}\", # WARNING : path must be an absolute path\n",
    "        backbone=backbone,\n",
    "        img_size=384, \n",
    "        identifier=\"curation250\",\n",
    "        nc=23,\n",
    "        classes=classes,\n",
    "        device=device,\n",
    "        epochs=250, \n",
    "        batch_size=64,\n",
    "        folds=1, \n",
    "        val_split=0.05,\n",
    "    )\n",
    "    trainer=YoloTrainer(conf)\n",
    "    trainer.train()\n",
    "\n",
    "    del trainer\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training models on dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode=\"msk_blk\"\n",
    "\n",
    "device=get_device()\n",
    "\n",
    "classes=['B', 'BA', 'EO', 'Er', 'LAM3', 'LF', 'LGL', 'LH_lyAct', 'LLC', 'LM', 'LY', 'LZMG', 'LyB', 'Lysee', 'M', 'MBL', 'MM', 'MO', 'MoB', 'PM', 'PNN', 'SS', 'Thromb']\n",
    "\n",
    "backbones=[\"yolo11n.pt\",\"yolov10n.pt\",\"yolov10s.pt\"]\n",
    "\n",
    "for backbone in backbones:\n",
    "    conf=YoloConfig(\n",
    "        dataset=f\"{data_folder}/Cytologia_{mode}\", # WARNING : path must be an absolute path\n",
    "        backbone=backbone,\n",
    "        img_size=384, \n",
    "        identifier=\"curation250\",\n",
    "        nc=23,\n",
    "        classes=classes,\n",
    "        device=device,\n",
    "        epochs=250, \n",
    "        batch_size=64,\n",
    "        folds=1, \n",
    "        val_split=0.05,\n",
    "    )\n",
    "    trainer=YoloTrainer(conf)\n",
    "    trainer.train()\n",
    "\n",
    "    del trainer\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training models on the uncurated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device=get_device()\n",
    "\n",
    "classes=['B', 'BA', 'EO', 'Er', 'LAM3', 'LF', 'LGL', 'LH_lyAct', 'LLC', 'LM', 'LY', 'LZMG', 'LyB', 'Lysee', 'M', 'MBL', 'MM', 'MO', 'MoB', 'PM', 'PNN', 'SS', 'Thromb']\n",
    "\n",
    "conf=YoloConfig(\n",
    "    dataset=f\"{data_folder}/Cytologia_yolo\", # WARNING : path must be an absolute path\n",
    "    img_size=384, \n",
    "    identifier=\"no_curation250\",\n",
    "    nc=23,\n",
    "    classes=classes,\n",
    "    device=device,\n",
    "    epochs=250, \n",
    "    batch_size=64,\n",
    "    folds=1, \n",
    "    val_split=0.05,\n",
    ")\n",
    "trainer=YoloTrainer(conf)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now completed training our seven models. For the inference process, please refer to the [`inference.ipynb`](inference.ipynb) file."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cytologia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
